{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides a tutorial on how to use the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets management is made simple. You can view the available datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gsitk.datasets.datasets import DatasetManager\n",
    "\n",
    "dm = DatasetManager()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the data is done once. For all datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dm.prepare_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['imdb', 'vader', 'semeval13', 'sst', 'multidomain', 'imdb_unsup', 'pl04', 'semeval14', 'sentiment140'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And for only one dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dm.prepare_datasets(['vader', 'pl05'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['vader', 'pl05'])\n"
     ]
    }
   ],
   "source": [
    "print(type(data))\n",
    "print(data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is a dict, in which each value is a pandas DataFrame with the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>polarity</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[somehow, i, was, blessed, with, some, really,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[yay, ., another, good, phone, interview, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>[we, were, number, deep, last, night, amp, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[lmao, allcaps, ,, amazing, allcaps, !]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>[two, words, that, should, die, this, year, :,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   polarity                                               text\n",
       "0         1  [somehow, i, was, blessed, with, some, really,...\n",
       "1         1       [yay, ., another, good, phone, interview, .]\n",
       "2         1  [we, were, number, deep, last, night, amp, the...\n",
       "3         1            [lmao, allcaps, ,, amazing, allcaps, !]\n",
       "4        -1  [two, words, that, should, die, this, year, :,..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['vader'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    2901\n",
       "-1    1299\n",
       "Name: polarity, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['vader']['polarity'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GSITK has utilities for preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simple ['my', 'grandmother', 'is', 'an', 'apple', '.', 'please', ',', 'believe', 'me', '!']\n",
      "twitter <user> please let me enter to the usa <allcaps> <hastag> thanks\n",
      "normalize ['my', 'grandmother', 'is', 'an', 'apple', '.', 'please', ',', 'believe', 'me', '!']\n"
     ]
    }
   ],
   "source": [
    "from gsitk.preprocess import simple, pprocess_twitter, normalize\n",
    "\n",
    "text = \"My grandmother is an apple. Please, believe me!\"\n",
    "twitter_text = \"@POTUS please let me enter to the USA #thanks\"\n",
    "\n",
    "print('simple', simple.preprocess(text))\n",
    "print('twitter', pprocess_twitter.preprocess(twitter_text))\n",
    "print('normalize', normalize.preprocess(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GSITK has a variety of feature extrators. For exaple, in order to use a word2vec model as feature extractor, write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gsitk.features.word2vec import Word2VecFeatures\n",
    "\n",
    "w2v_feat = Word2VecFeatures(w2v_model_path='/data/w2vmodel_500d_5mc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting features is made by the method `transform`. All feature extractors implement `transform`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 500)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed = w2v_feat.transform(data['imdb']['text'].values)\n",
    "transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If extracting the features is time consuming, you can save the features locally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gsitk.features import features\n",
    "\n",
    "features.save_features(transformed, 'w2v__sentiment40')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And you can load them later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04839503, -0.03920275,  0.01310699, ..., -0.01793178,\n",
       "         0.01850573,  0.01894511],\n",
       "       [ 0.02001294, -0.01502401, -0.0211135 , ..., -0.01764425,\n",
       "        -0.00566167,  0.02577729],\n",
       "       [ 0.01879481, -0.04025034, -0.02238391, ..., -0.01603499,\n",
       "         0.00581812,  0.03437515],\n",
       "       ..., \n",
       "       [ 0.01735126, -0.02752644, -0.02615537, ..., -0.00227182,\n",
       "         0.00647882,  0.01969421],\n",
       "       [ 0.01858013, -0.01519343, -0.01451839, ..., -0.00798909,\n",
       "         0.00773863,  0.04368705],\n",
       "       [ 0.03160627, -0.0360069 , -0.006861  , ..., -0.01662612,\n",
       "         0.00133611,  0.0172867 ]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.load_features('w2v__sentiment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation: difficult made easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ready = {}\n",
    "for data_k, data_v in data.items():\n",
    "    data_ready[data_k] = data_v.copy()\n",
    "    data_ready[data_k]['text'] = data_v['text'].apply(' '.join).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the pipelines exactly the same as in sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier()),\n",
    "])\n",
    "\n",
    "pipeline.fit(data_ready['vader']['text'].values,\n",
    "             data_ready['vader']['polarity'].values.astype(int))\n",
    "pipeline.name = 'pipeline_trained'\n",
    "pipeline.named_steps['vect'].name = 'myvect'\n",
    "pipeline.named_steps['tfidf'].name = 'mytfidf'\n",
    "pipeline.named_steps['clf'].name = 'mylogisticregressor'\n",
    "\n",
    "\n",
    "pipeline2 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier()),\n",
    "])\n",
    "\n",
    "pipeline2.fit(data_ready['pl05']['text'].values,\n",
    "              data_ready['pl05']['polarity'].values.astype(int))\n",
    "pipeline2.name = 'pipeline_trained2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let the `Evaluation` do its job: evaluate your pipelines!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Features</th>\n",
       "      <th>Model</th>\n",
       "      <th>CV</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vader</td>\n",
       "      <td>None</td>\n",
       "      <td>pipeline_trained__vader</td>\n",
       "      <td>False</td>\n",
       "      <td>0.992143</td>\n",
       "      <td>0.992596</td>\n",
       "      <td>0.988998</td>\n",
       "      <td>0.992128</td>\n",
       "      <td>0.992143</td>\n",
       "      <td>0.990772</td>\n",
       "      <td>vect(myvect) --&gt; tfidf(mytfidf) --&gt; clf(mylogi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vader</td>\n",
       "      <td>None</td>\n",
       "      <td>pipeline_trained2__vader</td>\n",
       "      <td>False</td>\n",
       "      <td>0.596429</td>\n",
       "      <td>0.630961</td>\n",
       "      <td>0.649194</td>\n",
       "      <td>0.608576</td>\n",
       "      <td>0.596429</td>\n",
       "      <td>0.59155</td>\n",
       "      <td>vect --&gt; tfidf --&gt; clf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pl05</td>\n",
       "      <td>None</td>\n",
       "      <td>pipeline_trained__pl05</td>\n",
       "      <td>False</td>\n",
       "      <td>0.578962</td>\n",
       "      <td>0.585842</td>\n",
       "      <td>0.579002</td>\n",
       "      <td>0.570405</td>\n",
       "      <td>0.578962</td>\n",
       "      <td>0.570422</td>\n",
       "      <td>vect(myvect) --&gt; tfidf(mytfidf) --&gt; clf(mylogi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pl05</td>\n",
       "      <td>None</td>\n",
       "      <td>pipeline_trained2__pl05</td>\n",
       "      <td>False</td>\n",
       "      <td>0.926788</td>\n",
       "      <td>0.926838</td>\n",
       "      <td>0.926787</td>\n",
       "      <td>0.926786</td>\n",
       "      <td>0.926788</td>\n",
       "      <td>0.926786</td>\n",
       "      <td>vect --&gt; tfidf --&gt; clf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset Features                     Model     CV  accuracy precision_macro  \\\n",
       "0   vader     None   pipeline_trained__vader  False  0.992143        0.992596   \n",
       "1   vader     None  pipeline_trained2__vader  False  0.596429        0.630961   \n",
       "2    pl05     None    pipeline_trained__pl05  False  0.578962        0.585842   \n",
       "3    pl05     None   pipeline_trained2__pl05  False  0.926788        0.926838   \n",
       "\n",
       "  recall_macro f1_weighted  f1_micro  f1_macro  \\\n",
       "0     0.988998    0.992128  0.992143  0.990772   \n",
       "1     0.649194    0.608576  0.596429   0.59155   \n",
       "2     0.579002    0.570405  0.578962  0.570422   \n",
       "3     0.926787    0.926786  0.926788  0.926786   \n",
       "\n",
       "                                         Description  \n",
       "0  vect(myvect) --> tfidf(mytfidf) --> clf(mylogi...  \n",
       "1                             vect --> tfidf --> clf  \n",
       "2  vect(myvect) --> tfidf(mytfidf) --> clf(mylogi...  \n",
       "3                             vect --> tfidf --> clf  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gsitk.evaluation.evaluation import Evaluation\n",
    "\n",
    "datasets_evaluation = {\n",
    "    'vader': data_ready['vader'],\n",
    "    'pl05': data_ready['pl05']\n",
    "}\n",
    "\n",
    "ev = Evaluation(tuples=None,\n",
    "                datasets=datasets_evaluation,\n",
    "                pipelines=[pipeline, pipeline2])\n",
    "ev.evaluate()\n",
    "ev.results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1., ...,  0.,  0.,  1.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gsitk.classifiers.vader import VaderClassifier\n",
    "\n",
    "vc = VaderClassifier()\n",
    "vc.predict(data_ready['vader']['text'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation: bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The evaluation process uses pipes. Pipe are a way of organizing the different elements of the evaluation. Pipes are represented by EvalTuples, that are a way of specifiying which datasets, features and classifiers we want to evaluate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For evaluating a set of models that predict from a set of features, `EvalTuple` are specified. The next example evaluates a simple logistic regressions model that uses word2vec features to predict the sentiment of the `IMDB` dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1,\n",
       "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd = SGDClassifier()\n",
    "\n",
    "# transformed is the features extracted from the IMDB dataset\n",
    "# to properly evaluate, separate in train and test \n",
    "# using the original dataset fold\n",
    "train_indices = (data['imdb']['fold'] == 'train').values\n",
    "test_indices =(data['imdb']['fold'] == 'test').values\n",
    "\n",
    "transformed_train = transformed[train_indices]\n",
    "transformed_test = transformed[test_indices]\n",
    "\n",
    "\n",
    "sgd.fit(transformed_train, data['imdb']['polarity'][train_indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the model, features and `EvalTuple` for the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gsitk.pipe import Model, Features, EvalTuple\n",
    "\n",
    "models = [Model(name='sgd', classifier=sgd)]\n",
    "\n",
    "feats = [Features(name='w2v__imdb_test', dataset='imdb', values=transformed_test)]\n",
    "\n",
    "ets = [EvalTuple(classifier='sgd', features='w2v__imdb_test', labels='imdb')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the evaluation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gsitk.evaluation.evaluation import Evaluation\n",
    "\n",
    "ev = Evaluation(datasets=data, features=feats, models=models, tuples=ets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Features</th>\n",
       "      <th>Model</th>\n",
       "      <th>CV</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_macro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>imdb</td>\n",
       "      <td>w2v__imdb_test</td>\n",
       "      <td>sgd</td>\n",
       "      <td>False</td>\n",
       "      <td>0.76164</td>\n",
       "      <td>0.782904</td>\n",
       "      <td>0.76164</td>\n",
       "      <td>0.757075</td>\n",
       "      <td>0.76164</td>\n",
       "      <td>0.757075</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dataset        Features Model     CV accuracy precision_macro recall_macro  \\\n",
       "0    imdb  w2v__imdb_test   sgd  False  0.76164        0.782904      0.76164   \n",
       "\n",
       "  f1_weighted f1_micro  f1_macro  \n",
       "0    0.757075  0.76164  0.757075  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the evaluation\n",
    "ev.evaluate()\n",
    "\n",
    "# view the results\n",
    "ev.results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
