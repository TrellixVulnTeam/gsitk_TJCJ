{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"GSITK project gsitk is a library on top of scikit-learn that eases the development process on NLP machine learning driven projects. It uses numpy , pandas and related libraries to easy the development. gsitk manages datasets, features, classifiers and evaluation techniques, so that writing an evaluation pipeline results fast and simple. It is designed to be compatible with scikit-learn's Pipeline . Installation and use Installation gsitk can be installed via pip, which is the recommended way: pip install gsitk Alternatively, gsitk can be installed by cloning this repository. Using gsitk gsitk saves into disk the datasets and some other necessary resources. By default, all these data are stored in /data . The environment variable $DATA_PATH can be set in order to specify an alternative directory. Feature extraction examples SIMON feature extractor gsitk includes the implementation of the SIMON feature extractor, presented in this paper . To use it, two things are needed: A sentiment lexicon A word embeddings model that is gensim compatible. For example, using only the lexicon from Bing Liu and a embeddings model that is in the current directory: from gsitk.features import simon from nltk.corpus import opinion_lexicon from gensim.models.keyedvectors import KeyedVectors lexicon = [list(opinion_lexicon.positive()), list(opinion_lexicon.negative())] embedding_model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True) simon_transformer = simon.Simon(lexicon=lexicon, n_lexicon_words=200, embedding=embedding_model) # simon_transformer has the fit() and transform() methods, so it can be used in a Pipeline To enhance performance, it is recommendable to use a more complete scikit-learn pipe that implements normalization and feature selection in conjuction with the SIMON feature extraction. from gsitk.features import simon simon_model = simon.Simon(lexicon=lexicon, n_lexicon_words=200, embedding=embedding_model) model = simon.simon_pipeline(simon_transformer=simon_model, percentile=25) # model also implements fit() and transform() Word2VecFeatures This feature extractor implements the generic word vector model presented in this paper . An example of use is shown below: from gsitk.features.word2vec import Word2VecFeatures text = [ ['my', 'cat', 'is', 'totally', 'happy'], ['my', 'dog', 'is', 'very', 'sad'], ] # path is set to a Word2Vec model # convolution parameter encondes pooling operation [average, maximum, minimum] w2v_extractor = Word2VecFeatures(w2v_model_path=path, w2v_format='google_txt', convolution=[1,0,0]) X = model.transform(text) # X is and array containing extrated features Cite In you use this module, please cite the following papers: Enhancing Deep Learning Sentiment Analysis with Ensemble Techniques in Social Applications @article{ARAQUE2017236, title = \"Enhancing deep learning sentiment analysis with ensemble techniques in social applications\", journal = \"Expert Systems with Applications\", volume = \"77\", pages = \"236 - 246\", year = \"2017\", issn = \"0957-4174\", doi = \"https://doi.org/10.1016/j.eswa.2017.02.002\", url = \"http://www.sciencedirect.com/science/article/pii/S0957417417300751\", author = \"Oscar Araque and Ignacio Corcuera-Platas and J. Fernando S\u00e1nchez-Rada and Carlos A. Iglesias\", keywords = \"Ensemble, Deep learning, Sentiment analysis, Machine learning, Natural language processing\" } A Semantic Similarity-based Perspective of Affect Lexicons for Sentiment Analysis @article{ARAQUE2019346, title = \"A semantic similarity-based perspective of affect lexicons for sentiment analysis\", journal = \"Knowledge-Based Systems\", volume = \"165\", pages = \"346 - 359\", year = \"2019\", issn = \"0950-7051\", doi = \"https://doi.org/10.1016/j.knosys.2018.12.005\", url = \"http://www.sciencedirect.com/science/article/pii/S0950705118305926\", author = \"Oscar Araque and Ganggao Zhu and Carlos A. Iglesias\", keywords = \"Sentiment analysis, Sentiment lexicon, Semantic similarity, Word embeddings\", } Support If you find bugs or want to make feature requests, please post an issue here . This project is under active development. Acknowledgements This research work is supported by the EC through the H2020 project MixedEmotions (Grant Agreement no: 141111), the Spanish Ministry of Economy under the R&D project Semola (TEC2015-68284-R) and the project EmoSpaces (RTC-2016-5053-7); by ITEA3 project SOMEDI (15011); and by MOSI-AGIL-CM (grant P2013/ICE-3019, co-funded by EU Structural Funds FSE and FEDER).","title":"Home"},{"location":"#gsitk-project","text":"gsitk is a library on top of scikit-learn that eases the development process on NLP machine learning driven projects. It uses numpy , pandas and related libraries to easy the development. gsitk manages datasets, features, classifiers and evaluation techniques, so that writing an evaluation pipeline results fast and simple. It is designed to be compatible with scikit-learn's Pipeline .","title":"GSITK project"},{"location":"#installation-and-use","text":"","title":"Installation and use"},{"location":"#installation","text":"gsitk can be installed via pip, which is the recommended way: pip install gsitk Alternatively, gsitk can be installed by cloning this repository.","title":"Installation"},{"location":"#using-gsitk","text":"gsitk saves into disk the datasets and some other necessary resources. By default, all these data are stored in /data . The environment variable $DATA_PATH can be set in order to specify an alternative directory.","title":"Using gsitk"},{"location":"#feature-extraction-examples","text":"","title":"Feature extraction examples"},{"location":"#simon-feature-extractor","text":"gsitk includes the implementation of the SIMON feature extractor, presented in this paper . To use it, two things are needed: A sentiment lexicon A word embeddings model that is gensim compatible. For example, using only the lexicon from Bing Liu and a embeddings model that is in the current directory: from gsitk.features import simon from nltk.corpus import opinion_lexicon from gensim.models.keyedvectors import KeyedVectors lexicon = [list(opinion_lexicon.positive()), list(opinion_lexicon.negative())] embedding_model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True) simon_transformer = simon.Simon(lexicon=lexicon, n_lexicon_words=200, embedding=embedding_model) # simon_transformer has the fit() and transform() methods, so it can be used in a Pipeline To enhance performance, it is recommendable to use a more complete scikit-learn pipe that implements normalization and feature selection in conjuction with the SIMON feature extraction. from gsitk.features import simon simon_model = simon.Simon(lexicon=lexicon, n_lexicon_words=200, embedding=embedding_model) model = simon.simon_pipeline(simon_transformer=simon_model, percentile=25) # model also implements fit() and transform()","title":"SIMON feature extractor"},{"location":"#word2vecfeatures","text":"This feature extractor implements the generic word vector model presented in this paper . An example of use is shown below: from gsitk.features.word2vec import Word2VecFeatures text = [ ['my', 'cat', 'is', 'totally', 'happy'], ['my', 'dog', 'is', 'very', 'sad'], ] # path is set to a Word2Vec model # convolution parameter encondes pooling operation [average, maximum, minimum] w2v_extractor = Word2VecFeatures(w2v_model_path=path, w2v_format='google_txt', convolution=[1,0,0]) X = model.transform(text) # X is and array containing extrated features","title":"Word2VecFeatures"},{"location":"#cite","text":"In you use this module, please cite the following papers: Enhancing Deep Learning Sentiment Analysis with Ensemble Techniques in Social Applications @article{ARAQUE2017236, title = \"Enhancing deep learning sentiment analysis with ensemble techniques in social applications\", journal = \"Expert Systems with Applications\", volume = \"77\", pages = \"236 - 246\", year = \"2017\", issn = \"0957-4174\", doi = \"https://doi.org/10.1016/j.eswa.2017.02.002\", url = \"http://www.sciencedirect.com/science/article/pii/S0957417417300751\", author = \"Oscar Araque and Ignacio Corcuera-Platas and J. Fernando S\u00e1nchez-Rada and Carlos A. Iglesias\", keywords = \"Ensemble, Deep learning, Sentiment analysis, Machine learning, Natural language processing\" } A Semantic Similarity-based Perspective of Affect Lexicons for Sentiment Analysis @article{ARAQUE2019346, title = \"A semantic similarity-based perspective of affect lexicons for sentiment analysis\", journal = \"Knowledge-Based Systems\", volume = \"165\", pages = \"346 - 359\", year = \"2019\", issn = \"0950-7051\", doi = \"https://doi.org/10.1016/j.knosys.2018.12.005\", url = \"http://www.sciencedirect.com/science/article/pii/S0950705118305926\", author = \"Oscar Araque and Ganggao Zhu and Carlos A. Iglesias\", keywords = \"Sentiment analysis, Sentiment lexicon, Semantic similarity, Word embeddings\", }","title":"Cite"},{"location":"#support","text":"If you find bugs or want to make feature requests, please post an issue here . This project is under active development.","title":"Support"},{"location":"#acknowledgements","text":"This research work is supported by the EC through the H2020 project MixedEmotions (Grant Agreement no: 141111), the Spanish Ministry of Economy under the R&D project Semola (TEC2015-68284-R) and the project EmoSpaces (RTC-2016-5053-7); by ITEA3 project SOMEDI (15011); and by MOSI-AGIL-CM (grant P2013/ICE-3019, co-funded by EU Structural Funds FSE and FEDER).","title":"Acknowledgements"},{"location":"classifiers/","text":"Classifiers gsitk offers a common interface, compatible with scikit-learn predictors for implementing classifiers. A classifier is a model that can be trained, or be already prepared to make predictions. Currently, gsitk has two classifier types: LexiconSum : made for a simple use of an annotated lexicon. VaderClassifier : wrapper for the popular Vader sentiment analysis classifer. Use of Lexicon Performs a sum over the words of a given document, using the annotations from a lexicon. It follows the lexicon's annotation schema. Normalizes the output to the range [-1, 0, 1]. The following example shows its use: from gsitk.classifiers import LexiconSum # use a custom-lexicon ls = LexiconSum({'good': 1, 'bad': -1, 'happy': 1, 'sad': -1, 'mildly': -0.1}) text = [ ['my', 'dog', 'is', 'a', 'good', 'and', 'happy', 'pet'], ['my', 'cat', 'is', 'not', 'sad', 'just', 'mildly', 'bad'], ['not', 'happy', 'nor', 'sad'], ] ls.predict(text) # output array([ 1., -1., 0.]) Vader Wrapper around the implementation of the original author. This module does not need the text tokenized, as seen in the following example: from gsitk.classifiers import VaderClassifier text = [ 'my dog is a good and happy pet', 'my cat is not sad just mildly bad', 'not happy nor sad', ] VaderClassifier().predict(text) # output array([ 1., 0., -1.])","title":"Classifiers"},{"location":"classifiers/#classifiers","text":"gsitk offers a common interface, compatible with scikit-learn predictors for implementing classifiers. A classifier is a model that can be trained, or be already prepared to make predictions. Currently, gsitk has two classifier types: LexiconSum : made for a simple use of an annotated lexicon. VaderClassifier : wrapper for the popular Vader sentiment analysis classifer.","title":"Classifiers"},{"location":"classifiers/#use-of-lexicon","text":"Performs a sum over the words of a given document, using the annotations from a lexicon. It follows the lexicon's annotation schema. Normalizes the output to the range [-1, 0, 1]. The following example shows its use: from gsitk.classifiers import LexiconSum # use a custom-lexicon ls = LexiconSum({'good': 1, 'bad': -1, 'happy': 1, 'sad': -1, 'mildly': -0.1}) text = [ ['my', 'dog', 'is', 'a', 'good', 'and', 'happy', 'pet'], ['my', 'cat', 'is', 'not', 'sad', 'just', 'mildly', 'bad'], ['not', 'happy', 'nor', 'sad'], ] ls.predict(text) # output array([ 1., -1., 0.])","title":"Use of Lexicon"},{"location":"classifiers/#vader","text":"Wrapper around the implementation of the original author. This module does not need the text tokenized, as seen in the following example: from gsitk.classifiers import VaderClassifier text = [ 'my dog is a good and happy pet', 'my cat is not sad just mildly bad', 'not happy nor sad', ] VaderClassifier().predict(text) # output array([ 1., 0., -1.])","title":"Vader"},{"location":"datasets/","text":"Datasets gsitk has a functionality suite for downloading, processing, and working with NLP datasets. This allows researchers to work seamlessly with common datasets without delving into the details of data munging. Dataset Manager interface Datasets can be accessed through the DatasetManager , an interface for dataset functionalities. The manager is accessed in the following manner: from gsitk.datasets.datasets import DatasetManager dm = DatasetManager() Dataset preparation includes downloading the data (if necessary) and pre-processing it. This is the main functionality of the DatasetManager , and can be accessed in this way: data = dm.prepare_datasets() The prepare_datasets methods downloads all available datasets (if necessary) and pre-process them, loading them into memory. Alternatively, it is possible to load a selection of datasets specifying theirs names: data = dm.prepare_datasets(['vader', 'pl05']) This example loads the vader and PL05 datasets. The prepare_datasets method returns a dict that contains the datasets. Each key corresponds the a dataset name, and the value is a pandas Dataframe . >>> data = dm.prepare_datasets(['vader', 'pl05']) >>> type(data) <class 'dict'> >>> data.keys() dict_keys(['vader', 'pl05']) >>> type(data['vader']) pandas.core.frame.DataFrame >>> data['vader'].head() polarity text 0 1 [somehow, i, was, blessed, with, some, really,... 1 1 [yay, ., another, good, phone, interview, .] 2 1 [we, were, number, deep, last, night, amp, the... 3 1 [lmao, allcaps, ,, amazing, allcaps, !] 4 -1 [two, words, that, should, die, this, year, :,... Datasets are stored in pandas format, all operations are so you can make all pandas-related operations: >>> data['vader']['polarity'].value_counts() 1 2901 -1 1299 Name: polarity, dtype: int64 Available datasets Here we publish a list of the available datasets in gsitk . IMDB [ imdb ] Link 50,000 sentiment analysis movie review instances, annotated with negative and positive . IMDB un-supervised [ imdb_unsup ] Link Additional unlabeled data, accompanying the IMDB dataset. Multi-Domain Sentiment Dataset (version 2.0) [ multidomain ] Link Product review from amazon. There are several domains. PL04 [ pl04 ] Link 1000 positive and 1000 negative processed reviews. Introduced in Pang/Lee ACL 2004. PL05 [ pl05 ] Link 5331 positive and 5331 negative processed sentences / snippets. Introduced in Pang/Lee ACL 2005. SemEval 2007 [ semeval07 ] Included in gsitk . No download necessary. Affective Text task dataset. Link . Annotated with emotions (e.g. joy, fear, surprise) and polarity orientation (positive/negative). SemEval 2013 [ semeval13 ] For legal reasons, this dataset needs to be obtained by the author. gsitk can process it then. Sentiment analysis task datasets from SemEval 2013. Link SemEval 2014 [ semeval14 ] For legal reasons, this dataset needs to be obtained by the author. gsitk can process it then. Sentiment analysis task datasets from SemEval 2014. Link Sentiment140 [ sentiment140 ] Link Dataset with 1,6 million tweets annotated with sentiment. Stanford Sentiment Treebank (SST) [ sst ] Link Detailed dataset with varied sentiment annotations. STS-Gold copurs [ sts ] Link Contains a dataset of tweets that have been human-annotated with sentiment labels. Vader [ vader ] Link A dataset of tweets annotated with sentiment. Used for the creation of the vader tools.","title":"Datasets"},{"location":"datasets/#datasets","text":"gsitk has a functionality suite for downloading, processing, and working with NLP datasets. This allows researchers to work seamlessly with common datasets without delving into the details of data munging.","title":"Datasets"},{"location":"datasets/#dataset-manager-interface","text":"Datasets can be accessed through the DatasetManager , an interface for dataset functionalities. The manager is accessed in the following manner: from gsitk.datasets.datasets import DatasetManager dm = DatasetManager() Dataset preparation includes downloading the data (if necessary) and pre-processing it. This is the main functionality of the DatasetManager , and can be accessed in this way: data = dm.prepare_datasets() The prepare_datasets methods downloads all available datasets (if necessary) and pre-process them, loading them into memory. Alternatively, it is possible to load a selection of datasets specifying theirs names: data = dm.prepare_datasets(['vader', 'pl05']) This example loads the vader and PL05 datasets. The prepare_datasets method returns a dict that contains the datasets. Each key corresponds the a dataset name, and the value is a pandas Dataframe . >>> data = dm.prepare_datasets(['vader', 'pl05']) >>> type(data) <class 'dict'> >>> data.keys() dict_keys(['vader', 'pl05']) >>> type(data['vader']) pandas.core.frame.DataFrame >>> data['vader'].head() polarity text 0 1 [somehow, i, was, blessed, with, some, really,... 1 1 [yay, ., another, good, phone, interview, .] 2 1 [we, were, number, deep, last, night, amp, the... 3 1 [lmao, allcaps, ,, amazing, allcaps, !] 4 -1 [two, words, that, should, die, this, year, :,... Datasets are stored in pandas format, all operations are so you can make all pandas-related operations: >>> data['vader']['polarity'].value_counts() 1 2901 -1 1299 Name: polarity, dtype: int64","title":"Dataset Manager interface"},{"location":"datasets/#available-datasets","text":"Here we publish a list of the available datasets in gsitk . IMDB [ imdb ] Link 50,000 sentiment analysis movie review instances, annotated with negative and positive . IMDB un-supervised [ imdb_unsup ] Link Additional unlabeled data, accompanying the IMDB dataset. Multi-Domain Sentiment Dataset (version 2.0) [ multidomain ] Link Product review from amazon. There are several domains. PL04 [ pl04 ] Link 1000 positive and 1000 negative processed reviews. Introduced in Pang/Lee ACL 2004. PL05 [ pl05 ] Link 5331 positive and 5331 negative processed sentences / snippets. Introduced in Pang/Lee ACL 2005. SemEval 2007 [ semeval07 ] Included in gsitk . No download necessary. Affective Text task dataset. Link . Annotated with emotions (e.g. joy, fear, surprise) and polarity orientation (positive/negative). SemEval 2013 [ semeval13 ] For legal reasons, this dataset needs to be obtained by the author. gsitk can process it then. Sentiment analysis task datasets from SemEval 2013. Link SemEval 2014 [ semeval14 ] For legal reasons, this dataset needs to be obtained by the author. gsitk can process it then. Sentiment analysis task datasets from SemEval 2014. Link Sentiment140 [ sentiment140 ] Link Dataset with 1,6 million tweets annotated with sentiment. Stanford Sentiment Treebank (SST) [ sst ] Link Detailed dataset with varied sentiment annotations. STS-Gold copurs [ sts ] Link Contains a dataset of tweets that have been human-annotated with sentiment labels. Vader [ vader ] Link A dataset of tweets annotated with sentiment. Used for the creation of the vader tools.","title":"Available datasets"},{"location":"evaluation/","text":"Evaluation gsitk implements several functionalities for managing complex evaluation scenarios in Sentiment Analysis. Evaluating new models, and comparing them against previous works is the bread and butter of progress in Sentiment Analysis (see this , por example). This way of progress makes the technicalities of the evaluation difficult to replicate, and costly to perform. In this sense, gsitk offers a number of functionalities to aid practitioners and researches in performing evaluation in the field of Sentiment Analysis. We divide the evaluation documentation in two: Basic Evaluation Advanced Evaluation Basic Evaluation As many of gsitk 's modules, the evaluation methods are compatible with scikit-learn's Pipelines . In fact, the we work with the evaluation interfaces as we do with these Pipelines. Let's perform a simple evaluation with gsitk from the beginning. First, we load the evaluation datasets: from gsitk.datasets.datasets import DatasetManager dm = DatasetManager() data = dm.prepare_datasets(['vader', 'pl05']) Following, we define the models we want to evaluate. We define two pipelines ( pipeline and pipeline2 ) that use scikit components. Observe that we are naming the pipelines and the pipelines' steps through the name property. This will be useful to locate each model. For pipeline2 , we do not name the pipeline's steps. from sklearn.pipeline import Pipeline from sklearn.feature_extraction.text import CountVectorizer from sklearn.feature_extraction.text import TfidfTransformer from sklearn.linear_model import SGDClassifier pipeline = Pipeline([ ('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', SGDClassifier()), ]) pipeline.fit(data_ready['vader']['text'].values, data_ready['vader']['polarity'].values.astype(int)) pipeline.name = 'pipeline_trained' pipeline.named_steps['vect'].name = 'myvect' pipeline.named_steps['tfidf'].name = 'mytfidf' pipeline.named_steps['clf'].name = 'mylogisticregressor' pipeline2 = Pipeline([ ('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', SGDClassifier()), ]) pipeline2.fit(data_ready['pl05']['text'].values, data_ready['pl05']['polarity'].values.astype(int)) pipeline2.name = 'pipeline_trained2' At this point, we may need to adapt the datasets so that the text is represented by a string, not a list of tokens: data_ready = {} for data_k, data_v in data.items(): data_ready[data_k] = data_v.copy() data_ready[data_k]['text'] = data_v['text'].apply(' '.join).values At this point we are ready to perform the evaluation. For this purpose, we use the Evaluation class, which is defined by the following parameters: tuples : used in Advanced Evaluation . datasets : a dict of the datasets to use for the evaluation. pipelines : a list of scikit pipelines that represent the models to evaluate. from gsitk.evaluation.evaluation import Evaluation # define datasets for evaluation datasets_evaluation = { 'vader': data_ready['vader'], 'pl05': data_ready['pl05'] } # configure evaluation ev = Evaluation(tuples=None, datasets=datasets_evaluation, pipelines=[pipeline, pipeline2]) # perform evaluation, this can take a little long ev.evaluate() # results are stored in ev, and are in pandas DataFrame format ev.results The output is shown below: | | Dataset | Features | Model | CV | accuracy | precision_macro | recall_macro | f1_weighted | f1_micro | f1_macro | Description | |---|---------|----------|--------------------------|-------|----------|-----------------|--------------|-------------|----------|----------|---------------------------------------------------| | 0 | vader | None | pipeline_trained__vader | False | 0.992143 | 0.992596 | 0.988998 | 0.992128 | 0.992143 | 0.990772 | vect(myvect) --> tfidf(mytfidf) --> clf(mylogi... | | 1 | vader | None | pipeline_trained2__vader | False | 0.596429 | 0.630961 | 0.649194 | 0.608576 | 0.596429 | 0.59155 | vect --> tfidf --> clf | | 2 | pl05 | None | pipeline_trained__pl05 | False | 0.578962 | 0.585842 | 0.579002 | 0.570405 | 0.578962 | 0.570422 | vect(myvect) --> tfidf(mytfidf) --> clf(mylogi... | | 3 | pl05 | None | pipeline_trained2__pl05 | False | 0.926788 | 0.926838 | 0.926787 | 0.926786 | 0.926788 | 0.926786 | vect --> tfidf --> clf | In the results table we can observe how the designed models obtain different metrics in the evaluation datasets. Also, the names we used when defining the models are used to identify each pipeline. When configured as in the example, Evaluation uses already trained models to predict on the defined datasets. For a more configurable framework, see Advanced Evaluation . Advanced Evaluation Of course, more complex evaluation methods normally need to be done. For this, gsitk 's evaluation framework has a more advanced interface. Internally, the evaluation process uses evaluation tuples ( EvalTuple ), which are a method for specifying which datasets, features and classifiers we want to evaluate. For evaluating a set of models that predict from a set of features, a `EvalTuple`` are specified. The next example evaluates a simple logistic regressions model that uses word2vec features to predict the sentiment of the IMDB dataset. We prepare the data and extract the features we want to evaluate: from gsitk.datasets.datasets import DatasetManager from gsitk.features.word2vec import Word2VecFeatures dm = DatasetManager() data = dm.prepare_datasets(['imdb',]) w2v_feat = Word2VecFeatures(w2v_model_path='/data/w2vmodel_500d_5mc') transformed = w2v_feat.transform(data['imdb']['text'].values) We define the machine learning model to use: from sklearn.linear_model import SGDClassifier sgd = SGDClassifier() # transformed is the features extracted from the IMDB dataset # to properly evaluate, separate in train and test # using the original dataset fold train_indices = (data['imdb']['fold'] == 'train').values test_indices =(data['imdb']['fold'] == 'test').values transformed_train = transformed[train_indices] transformed_test = transformed[test_indices] sgd.fit(transformed_train, data['imdb']['polarity'][train_indices]) After this, we prepare the model, features and EvalTuple for the evaluation: from gsitk.pipe import Model, Features, EvalTuple models = [Model(name='sgd', classifier=sgd)] feats = [Features(name='w2v__imdb_test', dataset='imdb', values=transformed_test)] ets = [EvalTuple(classifier='sgd', features='w2v__imdb_test', labels='imdb')] Finally, we just need to perform the evaluation: from gsitk.evaluation.evaluation import Evaluation ev = Evaluation(datasets=data, features=feats, models=models, tuples=ets) # run the evaluation ev.evaluate() # view the results ev.results The output is: | | Dataset | Features | Model | CV | accuracy | precision_macro | recall_macro | f1_weighted | f1_micro | f1_macro | |---|---------|----------------|-------|-------|----------|-----------------|--------------|-------------|----------|----------| | 0 | imdb | w2v__imdb_test | sgd | False | 0.76164 | 0.782904 | 0.76164 | 0.757075 | 0.76164 | 0.757075 | From the output, we can see how the evaluation has been done. Through the shown tools, we can define more complex evaluation procedures, adapting to the needs of practitioners and researchers. If we want to perform cross-validation , there is a specific evaluation tuple for that: the CrossEvalTuple , which has the same interface as the EvalTuple . The full example is shown below: from gsitk.datasets.datasets import DatasetManager from gsitk.features.word2vec import Word2VecFeatures from sklearn.linear_model import SGDClassifier from gsitk.pipe import Model, Features, EvalTuple from gsitk.evaluation.evaluation import Evaluation dm = DatasetManager() data = dm.prepare_datasets(['imdb',]) w2v_feat = Word2VecFeatures(w2v_model_path='/data/w2vmodel_500d_5mc') transformed = w2v_feat.transform(data['imdb']['text'].values) sgd = SGDClassifier() # transformed is the features extracted from the IMDB dataset # to properly evaluate, separate in train and test # using the original dataset fold train_indices = (data['imdb']['fold'] == 'train').values test_indices =(data['imdb']['fold'] == 'test').values transformed_train = transformed[train_indices] transformed_test = transformed[test_indices] sgd.fit(transformed_train, data['imdb']['polarity'][train_indices]) models = [Model(name='sgd', classifier=sgd)] feats = [Features(name='w2v__imdb_test', dataset='imdb', values=transformed_test)] ets = [EvalTuple(classifier='sgd', features='w2v__imdb_test', labels='imdb')] ev = Evaluation(datasets=data, features=feats, models=models, tuples=ets) # run the evaluation ev.evaluate() # view the results ev.results","title":"Evaluation"},{"location":"evaluation/#evaluation","text":"gsitk implements several functionalities for managing complex evaluation scenarios in Sentiment Analysis. Evaluating new models, and comparing them against previous works is the bread and butter of progress in Sentiment Analysis (see this , por example). This way of progress makes the technicalities of the evaluation difficult to replicate, and costly to perform. In this sense, gsitk offers a number of functionalities to aid practitioners and researches in performing evaluation in the field of Sentiment Analysis. We divide the evaluation documentation in two: Basic Evaluation Advanced Evaluation","title":"Evaluation"},{"location":"evaluation/#basic-evaluation","text":"As many of gsitk 's modules, the evaluation methods are compatible with scikit-learn's Pipelines . In fact, the we work with the evaluation interfaces as we do with these Pipelines. Let's perform a simple evaluation with gsitk from the beginning. First, we load the evaluation datasets: from gsitk.datasets.datasets import DatasetManager dm = DatasetManager() data = dm.prepare_datasets(['vader', 'pl05']) Following, we define the models we want to evaluate. We define two pipelines ( pipeline and pipeline2 ) that use scikit components. Observe that we are naming the pipelines and the pipelines' steps through the name property. This will be useful to locate each model. For pipeline2 , we do not name the pipeline's steps. from sklearn.pipeline import Pipeline from sklearn.feature_extraction.text import CountVectorizer from sklearn.feature_extraction.text import TfidfTransformer from sklearn.linear_model import SGDClassifier pipeline = Pipeline([ ('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', SGDClassifier()), ]) pipeline.fit(data_ready['vader']['text'].values, data_ready['vader']['polarity'].values.astype(int)) pipeline.name = 'pipeline_trained' pipeline.named_steps['vect'].name = 'myvect' pipeline.named_steps['tfidf'].name = 'mytfidf' pipeline.named_steps['clf'].name = 'mylogisticregressor' pipeline2 = Pipeline([ ('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', SGDClassifier()), ]) pipeline2.fit(data_ready['pl05']['text'].values, data_ready['pl05']['polarity'].values.astype(int)) pipeline2.name = 'pipeline_trained2' At this point, we may need to adapt the datasets so that the text is represented by a string, not a list of tokens: data_ready = {} for data_k, data_v in data.items(): data_ready[data_k] = data_v.copy() data_ready[data_k]['text'] = data_v['text'].apply(' '.join).values At this point we are ready to perform the evaluation. For this purpose, we use the Evaluation class, which is defined by the following parameters: tuples : used in Advanced Evaluation . datasets : a dict of the datasets to use for the evaluation. pipelines : a list of scikit pipelines that represent the models to evaluate. from gsitk.evaluation.evaluation import Evaluation # define datasets for evaluation datasets_evaluation = { 'vader': data_ready['vader'], 'pl05': data_ready['pl05'] } # configure evaluation ev = Evaluation(tuples=None, datasets=datasets_evaluation, pipelines=[pipeline, pipeline2]) # perform evaluation, this can take a little long ev.evaluate() # results are stored in ev, and are in pandas DataFrame format ev.results The output is shown below: | | Dataset | Features | Model | CV | accuracy | precision_macro | recall_macro | f1_weighted | f1_micro | f1_macro | Description | |---|---------|----------|--------------------------|-------|----------|-----------------|--------------|-------------|----------|----------|---------------------------------------------------| | 0 | vader | None | pipeline_trained__vader | False | 0.992143 | 0.992596 | 0.988998 | 0.992128 | 0.992143 | 0.990772 | vect(myvect) --> tfidf(mytfidf) --> clf(mylogi... | | 1 | vader | None | pipeline_trained2__vader | False | 0.596429 | 0.630961 | 0.649194 | 0.608576 | 0.596429 | 0.59155 | vect --> tfidf --> clf | | 2 | pl05 | None | pipeline_trained__pl05 | False | 0.578962 | 0.585842 | 0.579002 | 0.570405 | 0.578962 | 0.570422 | vect(myvect) --> tfidf(mytfidf) --> clf(mylogi... | | 3 | pl05 | None | pipeline_trained2__pl05 | False | 0.926788 | 0.926838 | 0.926787 | 0.926786 | 0.926788 | 0.926786 | vect --> tfidf --> clf | In the results table we can observe how the designed models obtain different metrics in the evaluation datasets. Also, the names we used when defining the models are used to identify each pipeline. When configured as in the example, Evaluation uses already trained models to predict on the defined datasets. For a more configurable framework, see Advanced Evaluation .","title":"Basic Evaluation"},{"location":"evaluation/#advanced-evaluation","text":"Of course, more complex evaluation methods normally need to be done. For this, gsitk 's evaluation framework has a more advanced interface. Internally, the evaluation process uses evaluation tuples ( EvalTuple ), which are a method for specifying which datasets, features and classifiers we want to evaluate. For evaluating a set of models that predict from a set of features, a `EvalTuple`` are specified. The next example evaluates a simple logistic regressions model that uses word2vec features to predict the sentiment of the IMDB dataset. We prepare the data and extract the features we want to evaluate: from gsitk.datasets.datasets import DatasetManager from gsitk.features.word2vec import Word2VecFeatures dm = DatasetManager() data = dm.prepare_datasets(['imdb',]) w2v_feat = Word2VecFeatures(w2v_model_path='/data/w2vmodel_500d_5mc') transformed = w2v_feat.transform(data['imdb']['text'].values) We define the machine learning model to use: from sklearn.linear_model import SGDClassifier sgd = SGDClassifier() # transformed is the features extracted from the IMDB dataset # to properly evaluate, separate in train and test # using the original dataset fold train_indices = (data['imdb']['fold'] == 'train').values test_indices =(data['imdb']['fold'] == 'test').values transformed_train = transformed[train_indices] transformed_test = transformed[test_indices] sgd.fit(transformed_train, data['imdb']['polarity'][train_indices]) After this, we prepare the model, features and EvalTuple for the evaluation: from gsitk.pipe import Model, Features, EvalTuple models = [Model(name='sgd', classifier=sgd)] feats = [Features(name='w2v__imdb_test', dataset='imdb', values=transformed_test)] ets = [EvalTuple(classifier='sgd', features='w2v__imdb_test', labels='imdb')] Finally, we just need to perform the evaluation: from gsitk.evaluation.evaluation import Evaluation ev = Evaluation(datasets=data, features=feats, models=models, tuples=ets) # run the evaluation ev.evaluate() # view the results ev.results The output is: | | Dataset | Features | Model | CV | accuracy | precision_macro | recall_macro | f1_weighted | f1_micro | f1_macro | |---|---------|----------------|-------|-------|----------|-----------------|--------------|-------------|----------|----------| | 0 | imdb | w2v__imdb_test | sgd | False | 0.76164 | 0.782904 | 0.76164 | 0.757075 | 0.76164 | 0.757075 | From the output, we can see how the evaluation has been done. Through the shown tools, we can define more complex evaluation procedures, adapting to the needs of practitioners and researchers. If we want to perform cross-validation , there is a specific evaluation tuple for that: the CrossEvalTuple , which has the same interface as the EvalTuple . The full example is shown below: from gsitk.datasets.datasets import DatasetManager from gsitk.features.word2vec import Word2VecFeatures from sklearn.linear_model import SGDClassifier from gsitk.pipe import Model, Features, EvalTuple from gsitk.evaluation.evaluation import Evaluation dm = DatasetManager() data = dm.prepare_datasets(['imdb',]) w2v_feat = Word2VecFeatures(w2v_model_path='/data/w2vmodel_500d_5mc') transformed = w2v_feat.transform(data['imdb']['text'].values) sgd = SGDClassifier() # transformed is the features extracted from the IMDB dataset # to properly evaluate, separate in train and test # using the original dataset fold train_indices = (data['imdb']['fold'] == 'train').values test_indices =(data['imdb']['fold'] == 'test').values transformed_train = transformed[train_indices] transformed_test = transformed[test_indices] sgd.fit(transformed_train, data['imdb']['polarity'][train_indices]) models = [Model(name='sgd', classifier=sgd)] feats = [Features(name='w2v__imdb_test', dataset='imdb', values=transformed_test)] ets = [EvalTuple(classifier='sgd', features='w2v__imdb_test', labels='imdb')] ev = Evaluation(datasets=data, features=feats, models=models, tuples=ets) # run the evaluation ev.evaluate() # view the results ev.results","title":"Advanced Evaluation"},{"location":"features/","text":"Features Feature extraction is of paramount importance in sentiment analysis and, more generally, Natural Language Processing. gsitk incorporates several utilities that implement a number of feature extraction techniques. Some of these techniques have been recently published in peer-reviewed publications, and are oriented to foster research. The list of feature extraction techniques implemented in gsitk is: Word2VecFeatures Doc2VecFeatures Simon SSWE Also, gsitk allows the user to persist and load already extracted features. This functionality is useful when a feature extraction process takes a long time, so you can persist the extracted features, for a posterior use. For more on this, see this section Word2VecFeatures This implementation corresponds to the M G presented in [Araque et al., 2017]. It uses a pre-trained word embedding model to extract a vector for each word, and then applies a pooling function to all words, obtaining document-level representation. By default, the pooling function is the average . The following example shows the use of the implementation: from gsitk.features.word2vec import Word2VecFeatures text = [ ['my', 'cat', 'is', 'totally', 'happy'], ['my', 'dog', 'is', 'very', 'sad'], ] # path is set to a Word2Vec model # convolution parameter encondes pooling operation [average, maximum, minimum] w2v_extractor = Word2VecFeatures( w2v_model_path=path, w2v_format='google_txt', convolution=[1,0,0]) X = model.transform(text) # X is and array containing extrated features The parameters are configured as follows: w2v_model_path : must contain a string path to a pre-trained word embedding model. w2v_format : can be gensim , google_txt , google_bin , depending on the model's format. gensim is aimed to use gensim models . google_txt and google_bin specify the use of the word2vec model for textual and binary representations, respectively. convolution : specifies the pooling function used. The coding is [average, maximum, minimum] . For example, [1,0,0] computes the average, [1, 0, 1] computes the average and minimum. Doc2VecFeatures Implementation of the method described in [Araque et al., 2017]. This offers a wrapper around the Doc2Vec model. This implementation extracts a document-level representation by using word-level vectors and combining them. As explained in the mentioned publication, using this rather that pure Word2Vec on long documents can improve results. The use is straightforward: from gsitk.features.doc2vec import Doc2VecFeatures text = [ ['my', 'cat', 'is', 'totally', 'happy'], ['my', 'dog', 'is', 'very', 'sad'], ] model = Doc2VecFeatures(path) d2v_features = model.transform(text) # this contains the vector representing each document The parameter that is inserted into the Doc2VecFeatures is the path to the model. SIMON This module implements the SIMilarity-based sentiment projectiON (SIMON) model, described in [Araque et al., 2019]. The main idea of the SIMON method is that given a domain lexicon, the input text is measured against it, computing a vector that encodes the similarity between the input text and the lexicon. Such a vector encodes the similarity, as given by the word embedding model, of each of the words of the analyzed text to the lexicon words. To use SIMON, two things are needed: A sentiment lexicon A word embeddings model that is gensim compatible. For example, using only the lexicon from Bing Liu and a embeddings model that is in the current directory: from gsitk.features import simon from nltk.corpus import opinion_lexicon from gensim.models.keyedvectors import KeyedVectors lexicon = [list(opinion_lexicon.positive()), list(opinion_lexicon.negative())] embedding_model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True) simon_transformer = simon.Simon(lexicon=lexicon, n_lexicon_words=200, embedding=embedding_model) # simon_transformer has the fit() and transform() methods, so it can be used in a Pipeline The parameters that can be used are: lexicon : where we insert the domain lexicon we want to use. n_lexicon_words : the number of maximum number of words to use from the lexicon. embedding : expects a word embedding model. This transformer implements the fit and transform methods from scikit-learn API , which allows us to insert SIMON in a Pipeline . The previous use of SIMON is simple, and can be improved. To enhance performance, it is recommendable to use a more complete scikit-learn Pipeline that implements normalization and feature selection in conjuction with the SIMON feature extraction: from gsitk.features import simon simon_model = simon.Simon(lexicon=lexicon, n_lexicon_words=200, embedding=embedding_model) model = simon.simon_pipeline(simon_transformer=simon_model, percentile=25) # model also implements fit() and transform() In this expanded version, the new parameters are: simon_transformer : where a Simon transformer must be passed. percentile : percentile for the selection of features. 25 would be retaining the 25% most informative features. Specifying a 100 would retain all features, without performing any filtering. SSWE This class implements the model and its exploitation as described in this paper [Araque et al., 2017]. The original model is proposed in this work [Tang et al., 2014]. Basically, this implementation uses the already trained sentiment-aware word embeddings, extracting a vector for each document. For this, it uses the sentiment-aware word embedding model, aggregating the component vectors into a document-level representation. Its use can be seen in the example: from gsitk.features.sswe import SSWE text = [ ['my', 'cat', 'is', 'glad'], ['my', 'dog', 'is', 'saddening'] ] model = SSWE() model.fit_transform(text) # output array([[-0.03692475, 0.69433968, -0.10123377, -0.20750073, -0.4521742 , -0.11163325, -0.6230624 , -0.31017193, 0.5679557 , 0.27609493, -0.30070497, -0.20598209, 0.62151025, -0.10289793, 0.0028881 , -0.64963145, -0.2537114 , -0.10160725, -0.13404223, 0.21716036, 0.1927223 , 0.33401577, -0.09717232, -0.47497711, 0.24664997, 0.12755613, -0.15305273, -0.22193395, -0.01209228, 0.05324505, 0.43930245, 0.00602835, -0.30367692, -0.70815245, -0.79096279, 0.10255207, -0.07759673, 0.40358937, -0.10322898, 0.44279148, 0.82335535, 0.31171023, 0.44288205, 0.2905347 , 0.46477 , 0.28904402, -0.55061338, 0.10661928, 0.46488735, 0.33304884], [-0.36602225, -0.58546405, 0.05227629, -0.21769451, 0.01021858, 0.8831138 , 0.19209097, -0.01067718, -0.34836705, -0.0732986 , -0.69389325, 0.00714602, -0.1676837 , 0.23442017, -0.388703 , 0.75398148, 0.51507288, 0.15459292, 0.322662 , 0.18878383, 0.3826721 , -0.09494013, -0.24824411, -0.07548841, 0.1644036 , 0.2624967 , 0.20364558, -0.40885403, -0.2868039 , 0.6564402 , 0.16390643, -0.35993635, -0.07133374, -0.2713782 , 0.6116734 , 0.02168057, -0.2557114 , 0.40677885, 0.35998122, 0.30713927, -0.62793042, -0.52468092, 0.01578745, -0.08235615, 0.06924792, -0.61774441, 0.78259982, -0.61167277, -0.21632402, -0.31093053]]) Persist and load Saving an already extracted feature set to load it later is very useful. There are times when extracting features takes a long time, and we need to persist those valuable features to disk. For this, use the persistence utility in gistk . See the example: # we have already loaded a built-in dataset: imdb from gsitk.features import features w2v_feat = Word2VecFeatures(w2v_model_path='/data/w2vmodel_500d_5mc') # this can take a long time transformed = w2v_feat.transform(data['imdb']['text'].values) # transformed.shape has (50000, 500) dimensions # we name the features for posterior recovery features.save_features(transformed, 'w2v__sentiment') # we load it later my_feats = features.load_features('w2v__sentiment') # my_feats has (50000, 500) dimensions [Araque et al., 2017] Oscar Araque, Ignacio Corcuera-Platas, J. Fernando S\u00e1nchez-Rada, Carlos A. Iglesias. Enhancing deep learning sentiment analysis with ensemble techniques in social applications, Expert Systems with Applications, Volume 77, 2017, Pages 236-246, ISSN 0957-4174, https://doi.org/10.1016/j.eswa.2017.02.002 [Araque et al., 2019] Oscar Araque, Ganggao Zhu, Carlos A. Iglesias. A semantic similarity-based perspective of affect lexicons for sentiment analysis, Knowledge-Based Systems, Volume 165, 2019, Pages 346-359, ISSN 0950-7051, https://doi.org/10.1016/j.knosys.2018.12.005 . [Tang et al., 2014] Tang, D., Wei, F., Yang, N., Zhou, M., Liu, T., & Qin, B. (2014, June). Learning sentiment-specific word embedding for twitter sentiment classification. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (pp. 1555-1565).","title":"Feature extraction"},{"location":"features/#features","text":"Feature extraction is of paramount importance in sentiment analysis and, more generally, Natural Language Processing. gsitk incorporates several utilities that implement a number of feature extraction techniques. Some of these techniques have been recently published in peer-reviewed publications, and are oriented to foster research. The list of feature extraction techniques implemented in gsitk is: Word2VecFeatures Doc2VecFeatures Simon SSWE Also, gsitk allows the user to persist and load already extracted features. This functionality is useful when a feature extraction process takes a long time, so you can persist the extracted features, for a posterior use. For more on this, see this section","title":"Features"},{"location":"features/#word2vecfeatures","text":"This implementation corresponds to the M G presented in [Araque et al., 2017]. It uses a pre-trained word embedding model to extract a vector for each word, and then applies a pooling function to all words, obtaining document-level representation. By default, the pooling function is the average . The following example shows the use of the implementation: from gsitk.features.word2vec import Word2VecFeatures text = [ ['my', 'cat', 'is', 'totally', 'happy'], ['my', 'dog', 'is', 'very', 'sad'], ] # path is set to a Word2Vec model # convolution parameter encondes pooling operation [average, maximum, minimum] w2v_extractor = Word2VecFeatures( w2v_model_path=path, w2v_format='google_txt', convolution=[1,0,0]) X = model.transform(text) # X is and array containing extrated features The parameters are configured as follows: w2v_model_path : must contain a string path to a pre-trained word embedding model. w2v_format : can be gensim , google_txt , google_bin , depending on the model's format. gensim is aimed to use gensim models . google_txt and google_bin specify the use of the word2vec model for textual and binary representations, respectively. convolution : specifies the pooling function used. The coding is [average, maximum, minimum] . For example, [1,0,0] computes the average, [1, 0, 1] computes the average and minimum.","title":"Word2VecFeatures"},{"location":"features/#doc2vecfeatures","text":"Implementation of the method described in [Araque et al., 2017]. This offers a wrapper around the Doc2Vec model. This implementation extracts a document-level representation by using word-level vectors and combining them. As explained in the mentioned publication, using this rather that pure Word2Vec on long documents can improve results. The use is straightforward: from gsitk.features.doc2vec import Doc2VecFeatures text = [ ['my', 'cat', 'is', 'totally', 'happy'], ['my', 'dog', 'is', 'very', 'sad'], ] model = Doc2VecFeatures(path) d2v_features = model.transform(text) # this contains the vector representing each document The parameter that is inserted into the Doc2VecFeatures is the path to the model.","title":"Doc2VecFeatures"},{"location":"features/#simon","text":"This module implements the SIMilarity-based sentiment projectiON (SIMON) model, described in [Araque et al., 2019]. The main idea of the SIMON method is that given a domain lexicon, the input text is measured against it, computing a vector that encodes the similarity between the input text and the lexicon. Such a vector encodes the similarity, as given by the word embedding model, of each of the words of the analyzed text to the lexicon words. To use SIMON, two things are needed: A sentiment lexicon A word embeddings model that is gensim compatible. For example, using only the lexicon from Bing Liu and a embeddings model that is in the current directory: from gsitk.features import simon from nltk.corpus import opinion_lexicon from gensim.models.keyedvectors import KeyedVectors lexicon = [list(opinion_lexicon.positive()), list(opinion_lexicon.negative())] embedding_model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True) simon_transformer = simon.Simon(lexicon=lexicon, n_lexicon_words=200, embedding=embedding_model) # simon_transformer has the fit() and transform() methods, so it can be used in a Pipeline The parameters that can be used are: lexicon : where we insert the domain lexicon we want to use. n_lexicon_words : the number of maximum number of words to use from the lexicon. embedding : expects a word embedding model. This transformer implements the fit and transform methods from scikit-learn API , which allows us to insert SIMON in a Pipeline . The previous use of SIMON is simple, and can be improved. To enhance performance, it is recommendable to use a more complete scikit-learn Pipeline that implements normalization and feature selection in conjuction with the SIMON feature extraction: from gsitk.features import simon simon_model = simon.Simon(lexicon=lexicon, n_lexicon_words=200, embedding=embedding_model) model = simon.simon_pipeline(simon_transformer=simon_model, percentile=25) # model also implements fit() and transform() In this expanded version, the new parameters are: simon_transformer : where a Simon transformer must be passed. percentile : percentile for the selection of features. 25 would be retaining the 25% most informative features. Specifying a 100 would retain all features, without performing any filtering.","title":"SIMON"},{"location":"features/#sswe","text":"This class implements the model and its exploitation as described in this paper [Araque et al., 2017]. The original model is proposed in this work [Tang et al., 2014]. Basically, this implementation uses the already trained sentiment-aware word embeddings, extracting a vector for each document. For this, it uses the sentiment-aware word embedding model, aggregating the component vectors into a document-level representation. Its use can be seen in the example: from gsitk.features.sswe import SSWE text = [ ['my', 'cat', 'is', 'glad'], ['my', 'dog', 'is', 'saddening'] ] model = SSWE() model.fit_transform(text) # output array([[-0.03692475, 0.69433968, -0.10123377, -0.20750073, -0.4521742 , -0.11163325, -0.6230624 , -0.31017193, 0.5679557 , 0.27609493, -0.30070497, -0.20598209, 0.62151025, -0.10289793, 0.0028881 , -0.64963145, -0.2537114 , -0.10160725, -0.13404223, 0.21716036, 0.1927223 , 0.33401577, -0.09717232, -0.47497711, 0.24664997, 0.12755613, -0.15305273, -0.22193395, -0.01209228, 0.05324505, 0.43930245, 0.00602835, -0.30367692, -0.70815245, -0.79096279, 0.10255207, -0.07759673, 0.40358937, -0.10322898, 0.44279148, 0.82335535, 0.31171023, 0.44288205, 0.2905347 , 0.46477 , 0.28904402, -0.55061338, 0.10661928, 0.46488735, 0.33304884], [-0.36602225, -0.58546405, 0.05227629, -0.21769451, 0.01021858, 0.8831138 , 0.19209097, -0.01067718, -0.34836705, -0.0732986 , -0.69389325, 0.00714602, -0.1676837 , 0.23442017, -0.388703 , 0.75398148, 0.51507288, 0.15459292, 0.322662 , 0.18878383, 0.3826721 , -0.09494013, -0.24824411, -0.07548841, 0.1644036 , 0.2624967 , 0.20364558, -0.40885403, -0.2868039 , 0.6564402 , 0.16390643, -0.35993635, -0.07133374, -0.2713782 , 0.6116734 , 0.02168057, -0.2557114 , 0.40677885, 0.35998122, 0.30713927, -0.62793042, -0.52468092, 0.01578745, -0.08235615, 0.06924792, -0.61774441, 0.78259982, -0.61167277, -0.21632402, -0.31093053]])","title":"SSWE"},{"location":"features/#persist-and-load","text":"Saving an already extracted feature set to load it later is very useful. There are times when extracting features takes a long time, and we need to persist those valuable features to disk. For this, use the persistence utility in gistk . See the example: # we have already loaded a built-in dataset: imdb from gsitk.features import features w2v_feat = Word2VecFeatures(w2v_model_path='/data/w2vmodel_500d_5mc') # this can take a long time transformed = w2v_feat.transform(data['imdb']['text'].values) # transformed.shape has (50000, 500) dimensions # we name the features for posterior recovery features.save_features(transformed, 'w2v__sentiment') # we load it later my_feats = features.load_features('w2v__sentiment') # my_feats has (50000, 500) dimensions [Araque et al., 2017] Oscar Araque, Ignacio Corcuera-Platas, J. Fernando S\u00e1nchez-Rada, Carlos A. Iglesias. Enhancing deep learning sentiment analysis with ensemble techniques in social applications, Expert Systems with Applications, Volume 77, 2017, Pages 236-246, ISSN 0957-4174, https://doi.org/10.1016/j.eswa.2017.02.002 [Araque et al., 2019] Oscar Araque, Ganggao Zhu, Carlos A. Iglesias. A semantic similarity-based perspective of affect lexicons for sentiment analysis, Knowledge-Based Systems, Volume 165, 2019, Pages 346-359, ISSN 0950-7051, https://doi.org/10.1016/j.knosys.2018.12.005 . [Tang et al., 2014] Tang, D., Wei, F., Yang, N., Zhou, M., Liu, T., & Qin, B. (2014, June). Learning sentiment-specific word embedding for twitter sentiment classification. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (pp. 1555-1565).","title":"Persist and load"},{"location":"preprocessing/","text":"Pre-processing As a NLP-centered software, gsitk has various functionalities for pre-processing tasks. Pre-processing is a central part of data munging in NLP, and more specifically, in sentiment analysis. In order to ease this kind of operation, gsitk offers the following type of pre-processers: Simple : the simple and more efficient pre-processor. Indicated for processing large datasets, as it is the fastest. Based on regular expressions that parse English text. Pre-process Twitter : a processor indicated for parsing Twitter text. Also based on regular expressions, extracts common emoji as special tokens, and transforms hashtags and mentions, normalizing them. Normalize : An all-purpose pre-processor. It is not as efficient as the other options, and performs word tokenization based on NLTK. Direct use The more straight-forward way to use the pre-processing utilities is presented as follows: from gsitk.preprocess import simple, pprocess_twitter, normalize text = \"My grandmother is an apple. Please, believe me!\" twitter_text = \"@POTUS please let me enter to the USA #thanks\" print('simple', simple.preprocess(text)) print('twitter', pprocess_twitter.preprocess(twitter_text)) print('normalize', normalize.preprocess(text)) These lines of code would output the following. Note how the Twitter data is transformed, normalizing the mention to an user and a hashtag. simple ['my', 'grandmother', 'is', 'an', 'apple', '.', 'please', ',', 'believe', 'me', '!'] twitter <user> please let me enter to the usa <allcaps> <hastag> thanks normalize ['my', 'grandmother', 'is', 'an', 'apple', '.', 'please', ',', 'believe', 'me', '!'] Preprocesser interface To facilitate the use of the preprocessing functions, gsitk offers an interface that is compatible with scikit-learn Pipelines : the Preprocesser . A simple script using this interface is: from gsitk.preprocess import pprocess_twitter, Preprocesser texts = [ \"@POTUS please let me enter to the USA #thanks\", \"If only Bradley's arm was longer. Best photo ever. #oscars\" ] Preprocesser(pprocess_twitter).transform(texts) # output: array(['<user> please let me enter to the usa <allcaps> <hastag> thanks', \"if only bradley's arm was longer. best photo ever. <hastag> oscars\"], dtype='<U66') The compatibility with scikit Pipelines can be used to ease the use of preprocessing. For example: from sklearn.pipeline import Pipeline from gsitk.preprocess import normalize, Preprocesser, JoinTransformer texts = [ \"This cat is crazy, he is not on the mat!\", \"Will no one rid me of this turbulent priest?\" ] preprocessing_pipe = Pipeline([ ('twitter', Preprocesser(normalize)), ('join', JoinTransformer()) ]) preprocessing_pipe.fit_transform(texts) # output: ['this cat is crazy , he is not on the mat !', 'will no one rid me of this turbulent priest ?'] Stop word removal Removing stop words is a pervasive task in NLP. gsitk includes a functionality for this, using the stop word collections in NLTK. from gsitk.preprocess.stopwords import StopWordsRemover texts = [ \"this cat is crazy , he is not on the mat !\", \"will no one rid me of this turbulent priest ?\" ] StopWordsRemover().fit_transform(texts) # output: ['cat crazy , mat !', 'one rid turbulent priest ?'] As it uses the NLTK stop word collections, several languages can be parsed, as in this Spanish example. from gsitk.preprocess.stopwords import StopWordsRemover texts = [ \"entre el clavel blanco y la rosa roja , su majestad escoja\", \"con diez ca\u00f1ones por banda viento en popa a toda vela\", ] StopWordsRemover(language='spanish').fit_transform(texts) # output: ['clavel blanco rosa roja , majestad escoja', 'diez ca\u00f1ones banda viento popa toda vela'] Embeddings trick The paper DepecheMood++: a Bilingual Emotion Lexicon Built Through Simple Yet Powerful Techniques ( link here ) introduces a technique called the Embeddings trick . In short, it consists on replacing certain words by others using a word embedding model. It is used to expand an existing emotion dictionary. In any way, we consider it is an useful technique, and has been implemented in gsitk , making it easier to replicate the mentioned paper. This technique is used to avoid OOV (Out Of Vocabulary) issues when using a limited lexicon. Consider the following reduces sentiment analysis example: from gsitk.preprocess.embeddings_trick import EmbeddingsTricker et = EmbeddingsTricker( model_path='projects/data/WordEmbeddings/eng/GoogleNews-vectors-negative300.bin', w2v_format='google_bin', vocabulary=['my', 'cat', 'is', 'dog'], ) ex_text = [ ['my', 'cat', 'is', 'glad'], ['my', 'dog', 'is', 'saddening'] ] et.fit_transform(ex_text) # output [['my', 'cat', 'is', 'happy'], ['my', 'dog', 'is', 'sad']] For more details on how to load and use the word embeddings for EmbeddingsTricker , see features .","title":"Preprocessing"},{"location":"preprocessing/#pre-processing","text":"As a NLP-centered software, gsitk has various functionalities for pre-processing tasks. Pre-processing is a central part of data munging in NLP, and more specifically, in sentiment analysis. In order to ease this kind of operation, gsitk offers the following type of pre-processers: Simple : the simple and more efficient pre-processor. Indicated for processing large datasets, as it is the fastest. Based on regular expressions that parse English text. Pre-process Twitter : a processor indicated for parsing Twitter text. Also based on regular expressions, extracts common emoji as special tokens, and transforms hashtags and mentions, normalizing them. Normalize : An all-purpose pre-processor. It is not as efficient as the other options, and performs word tokenization based on NLTK.","title":"Pre-processing"},{"location":"preprocessing/#direct-use","text":"The more straight-forward way to use the pre-processing utilities is presented as follows: from gsitk.preprocess import simple, pprocess_twitter, normalize text = \"My grandmother is an apple. Please, believe me!\" twitter_text = \"@POTUS please let me enter to the USA #thanks\" print('simple', simple.preprocess(text)) print('twitter', pprocess_twitter.preprocess(twitter_text)) print('normalize', normalize.preprocess(text)) These lines of code would output the following. Note how the Twitter data is transformed, normalizing the mention to an user and a hashtag. simple ['my', 'grandmother', 'is', 'an', 'apple', '.', 'please', ',', 'believe', 'me', '!'] twitter <user> please let me enter to the usa <allcaps> <hastag> thanks normalize ['my', 'grandmother', 'is', 'an', 'apple', '.', 'please', ',', 'believe', 'me', '!']","title":"Direct use"},{"location":"preprocessing/#preprocesser-interface","text":"To facilitate the use of the preprocessing functions, gsitk offers an interface that is compatible with scikit-learn Pipelines : the Preprocesser . A simple script using this interface is: from gsitk.preprocess import pprocess_twitter, Preprocesser texts = [ \"@POTUS please let me enter to the USA #thanks\", \"If only Bradley's arm was longer. Best photo ever. #oscars\" ] Preprocesser(pprocess_twitter).transform(texts) # output: array(['<user> please let me enter to the usa <allcaps> <hastag> thanks', \"if only bradley's arm was longer. best photo ever. <hastag> oscars\"], dtype='<U66') The compatibility with scikit Pipelines can be used to ease the use of preprocessing. For example: from sklearn.pipeline import Pipeline from gsitk.preprocess import normalize, Preprocesser, JoinTransformer texts = [ \"This cat is crazy, he is not on the mat!\", \"Will no one rid me of this turbulent priest?\" ] preprocessing_pipe = Pipeline([ ('twitter', Preprocesser(normalize)), ('join', JoinTransformer()) ]) preprocessing_pipe.fit_transform(texts) # output: ['this cat is crazy , he is not on the mat !', 'will no one rid me of this turbulent priest ?']","title":"Preprocesser interface"},{"location":"preprocessing/#stop-word-removal","text":"Removing stop words is a pervasive task in NLP. gsitk includes a functionality for this, using the stop word collections in NLTK. from gsitk.preprocess.stopwords import StopWordsRemover texts = [ \"this cat is crazy , he is not on the mat !\", \"will no one rid me of this turbulent priest ?\" ] StopWordsRemover().fit_transform(texts) # output: ['cat crazy , mat !', 'one rid turbulent priest ?'] As it uses the NLTK stop word collections, several languages can be parsed, as in this Spanish example. from gsitk.preprocess.stopwords import StopWordsRemover texts = [ \"entre el clavel blanco y la rosa roja , su majestad escoja\", \"con diez ca\u00f1ones por banda viento en popa a toda vela\", ] StopWordsRemover(language='spanish').fit_transform(texts) # output: ['clavel blanco rosa roja , majestad escoja', 'diez ca\u00f1ones banda viento popa toda vela']","title":"Stop word removal"},{"location":"preprocessing/#embeddings-trick","text":"The paper DepecheMood++: a Bilingual Emotion Lexicon Built Through Simple Yet Powerful Techniques ( link here ) introduces a technique called the Embeddings trick . In short, it consists on replacing certain words by others using a word embedding model. It is used to expand an existing emotion dictionary. In any way, we consider it is an useful technique, and has been implemented in gsitk , making it easier to replicate the mentioned paper. This technique is used to avoid OOV (Out Of Vocabulary) issues when using a limited lexicon. Consider the following reduces sentiment analysis example: from gsitk.preprocess.embeddings_trick import EmbeddingsTricker et = EmbeddingsTricker( model_path='projects/data/WordEmbeddings/eng/GoogleNews-vectors-negative300.bin', w2v_format='google_bin', vocabulary=['my', 'cat', 'is', 'dog'], ) ex_text = [ ['my', 'cat', 'is', 'glad'], ['my', 'dog', 'is', 'saddening'] ] et.fit_transform(ex_text) # output [['my', 'cat', 'is', 'happy'], ['my', 'dog', 'is', 'sad']] For more details on how to load and use the word embeddings for EmbeddingsTricker , see features .","title":"Embeddings trick"},{"location":"publications/","text":"Publications gsitk is used in several publications. The Word2VecFeatures and Evaluation methods are used extensively in: Oscar Araque, Ignacio Corcuera-Platas, J. Fernando S\u00e1nchez-Rada, Carlos A. Iglesias. Enhancing deep learning sentiment analysis with ensemble techniques in social applications, Expert Systems with Applications, Volume 77, 2017, Pages 236-246, ISSN 0957-4174. https://doi.org/10.1016/j.eswa.2017.02.002 . The SIMON model is proposed and evaluated in: Oscar Araque, Ganggao Zhu, Carlos A. Iglesias. A semantic similarity-based perspective of affect lexicons for sentiment analysis, Knowledge-Based Systems, Volume 165, 2019, Pages 346-359, ISSN 0950-7051. https://doi.org/10.1016/j.knosys.2018.12.005 . The SIMON model is used for other NLP domains: radicalization dectection and moral value estimation. Oscar Araque and Carlos A. Iglesias, An Approach for Radicalization Detection Based on Emotion Signals and Semantic Similarity, in IEEE Access, vol. 8, pp. 17877-17891, 2020. https://doi.org/10.1109/ACCESS.2020.2967219 Oscar Araque, Lorenzo Gatti, Kyriaki Kalimeri. MoralStrength: Exploiting a moral lexicon and embedding similarity for moral foundations prediction, Knowledge-Based Systems, Volume 191, 2020, 105184, ISSN 0950-7051, https://doi.org/10.1016/j.knosys.2019.105184 The embedding trick method is presented and evaluation in: O. Araque, L. Gatti, J. Staiano and M. Guerini. DepecheMood++: a Bilingual Emotion Lexicon Built Through Simple Yet Powerful Techniques, in IEEE Transactions on Affective Computing, https://doi.org/10.1109/TAFFC.2019.2934444","title":"Publications"},{"location":"publications/#publications","text":"gsitk is used in several publications. The Word2VecFeatures and Evaluation methods are used extensively in: Oscar Araque, Ignacio Corcuera-Platas, J. Fernando S\u00e1nchez-Rada, Carlos A. Iglesias. Enhancing deep learning sentiment analysis with ensemble techniques in social applications, Expert Systems with Applications, Volume 77, 2017, Pages 236-246, ISSN 0957-4174. https://doi.org/10.1016/j.eswa.2017.02.002 . The SIMON model is proposed and evaluated in: Oscar Araque, Ganggao Zhu, Carlos A. Iglesias. A semantic similarity-based perspective of affect lexicons for sentiment analysis, Knowledge-Based Systems, Volume 165, 2019, Pages 346-359, ISSN 0950-7051. https://doi.org/10.1016/j.knosys.2018.12.005 . The SIMON model is used for other NLP domains: radicalization dectection and moral value estimation. Oscar Araque and Carlos A. Iglesias, An Approach for Radicalization Detection Based on Emotion Signals and Semantic Similarity, in IEEE Access, vol. 8, pp. 17877-17891, 2020. https://doi.org/10.1109/ACCESS.2020.2967219 Oscar Araque, Lorenzo Gatti, Kyriaki Kalimeri. MoralStrength: Exploiting a moral lexicon and embedding similarity for moral foundations prediction, Knowledge-Based Systems, Volume 191, 2020, 105184, ISSN 0950-7051, https://doi.org/10.1016/j.knosys.2019.105184 The embedding trick method is presented and evaluation in: O. Araque, L. Gatti, J. Staiano and M. Guerini. DepecheMood++: a Bilingual Emotion Lexicon Built Through Simple Yet Powerful Techniques, in IEEE Transactions on Affective Computing, https://doi.org/10.1109/TAFFC.2019.2934444","title":"Publications"}]}